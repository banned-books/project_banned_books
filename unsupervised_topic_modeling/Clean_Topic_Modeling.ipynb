{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPUShazuxppdWQZ8RxWoCgw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banned-books/project_banned_books/blob/main/unsupervised_topic_modeling/Clean_Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount GDrive\n"
      ],
      "metadata": {
        "id": "Cnn-WwhJvyqY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kebz_Ju7vu8a",
        "outputId": "340da57b-e2a4-4aae-d6a7-4281c7757003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "kUk2mYFqv5F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy import linalg\n",
        "import gensim\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import matplotlib\n",
        "import scattertext as st\n",
        "import seaborn as sns\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "%matplotlib inline\n",
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "id": "fCOItnfRv2pW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9ed9f0-c6c6-4ec1-ca3f-b24c54a10521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Banned Book Data"
      ],
      "metadata": {
        "id": "YgUGWBBzwB9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/original_data/banned_books.csv')\n",
        "df['origin_of_challenge'] = df['origin_of_challenge'].replace(['Other'], 'Administrator')"
      ],
      "metadata": {
        "id": "7mdm5oK6wEZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Amazon.com Review Data"
      ],
      "metadata": {
        "id": "_S0OiPlFVgeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Description of columns in the file:\n",
        "\n",
        "- product_name - name of book + author\n",
        "- title - title of book review\n",
        "- body - text of the review\n",
        "- rating - rating of the book review\n",
        "- verified_purchase - did the reviewer buy the book or not?\n",
        "- review_date - the date of the review"
      ],
      "metadata": {
        "id": "KgjCG6DnWQPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_reviews = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/original_data/scraped_amz_reviews.csv')\n",
        "raw_reviews.head(3)"
      ],
      "metadata": {
        "id": "P7sC_ntnVivk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_reviews.info()"
      ],
      "metadata": {
        "id": "qP0cHAM0WqI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Process Banned Books Metadata\n"
      ],
      "metadata": {
        "id": "2gQ5mGBtwIdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def topnwords(documents, mode, n):\n",
        "    \"\"\"\n",
        "    returns list with top n most important/popular words using \n",
        "    tf-idf or count\n",
        "    \"\"\"\n",
        "    if mode == \"count\":\n",
        "        obj = CountVectorizer(lowercase=True, stop_words=\"english\")\n",
        "        word_occ = obj.fit_transform(documents)\n",
        "\n",
        "    elif mode == \"tf-idf\":\n",
        "        obj = TfidfVectorizer(lowercase=True, stop_words=\"english\")\n",
        "        word_occ = obj.fit_transform(documents)\n",
        "\n",
        "    text_features = pd.DataFrame(word_occ.toarray(), columns=obj.get_feature_names_out())\n",
        "\n",
        "    # Get the top 10 words per book\n",
        "    topwords = text_features.apply(\n",
        "        lambda s, n: pd.Series(s.nlargest(n).index), axis=1, n=n\n",
        "    )\n",
        "\n",
        "    return topwords.values.tolist()\n",
        "\n",
        "def filter_common_words(words):\n",
        "    common_words = [\n",
        "        \"desmond\",\n",
        "        \"new\", \n",
        "        \"york\",\n",
        "        \"times\",\n",
        "        \"bestselling\"\n",
        "    ]\n",
        "    return [word for word in words if word not in common_words]\n",
        "\n",
        "def preprocess_banned_books(df):\n",
        "    \"\"\"\n",
        "    This function does the text preprocessing\n",
        "    :return df\n",
        "    \"\"\"\n",
        "    # put all characters in lower case\n",
        "    df['text'] = df['title'] + ' ' + df['goodreads_tags'] + ' ' + df['goodreads_description']\n",
        "    df['text'] = df[\"text\"].str.lower()\n",
        "\n",
        "    # tokenization\n",
        "    df[\"Tokens\"] = df[\"text\"].apply(lambda x: nltk.word_tokenize(str(x)))\n",
        "\n",
        "    # remove stop words and non-alphabetic from all the text\n",
        "    sw = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "    df[\"Tokens\"] = df[\"Tokens\"].apply(\n",
        "        lambda x: [w for w in x if (w not in sw) and w.isalpha()]\n",
        "    )\n",
        "    \n",
        "    df['Tokens'] = df['Tokens'].apply(filter_common_words)\n",
        "    df['Joined_Tokens']= df['Tokens'].apply(lambda x: \" \".join(x))\n",
        "    df = df.sort_values(by = ['ban_date']).reset_index(drop = True)\n",
        "\n",
        "    # create top 10 words per book using tf-idf score\n",
        "    top_10_words = topnwords(df['Joined_Tokens'],  \"tf-idf\", n=10)\n",
        "    top_10_words = pd.DataFrame({'top_10_words':top_10_words})\n",
        "    df = pd.concat([df,top_10_words], axis = 1)\n",
        "\n",
        "    # create a scattertext object for Scattertext visualization\n",
        "    df['parse'] = df.Joined_Tokens.apply(st.whitespace_nlp_with_sentences)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "yVdznZ0UwHbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df = preprocess_banned_books(df)"
      ],
      "metadata": {
        "id": "SS8ygGV9wU0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df.head(1)"
      ],
      "metadata": {
        "id": "UQM8EuAhwZGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Process Amazon.com Reviews Data"
      ],
      "metadata": {
        "id": "tuYly2BNVNQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### About the data\n",
        "- We have a total of 380,639 reviews after removing duplicates below.\n",
        "- We have 3,594 duplicated reviews."
      ],
      "metadata": {
        "id": "cGW1cziOWyD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_reviews():\n",
        "  \"\"\"Pre-process reviews.\"\"\"\n",
        "\n",
        "  # Make a copy of the original dataframe\n",
        "  clean_data = raw_reviews.copy()\n",
        "\n",
        "  # Drop the duplicated reviews\n",
        "  clean_data.drop_duplicates(inplace = True)\n",
        "\n",
        "  # Concatenate the title and body (keep text column) and clean review date column\n",
        "  # clean_data = clean_data[['title', 'body', 'review_date']]\n",
        "  clean_data['reviews'] = clean_data['title'] + \" \" + clean_data['body']\n",
        "  clean_data = clean_data.drop(['title', 'body'], axis=1)\n",
        "  clean_data['reviews'] = clean_data['reviews'].astype(str)\n",
        "  clean_data['review_date'] = clean_data['review_date'].apply(pd.to_datetime)\n",
        "\n",
        "  # Lower case\n",
        "  clean_data['pre_process'] = clean_data['reviews'].apply(lambda x: str(x).lower()) \n",
        "\n",
        "  # Remove numbers\n",
        "  clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: re.sub(r'\\d+','', x))\n",
        "\n",
        "  # Remove extra spaces\n",
        "  clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: re.sub(' +', ' ', x))\n",
        "  clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: x.strip())\n",
        "\n",
        "  # Remove punctuation\n",
        "  clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n",
        "\n",
        "  # Grab the rating string\n",
        "  clean_data['rating'] = clean_data['rating'].astype(str).str[:1]\n",
        "\n",
        "  # Drop reviews without ratings\n",
        "  clean_data = clean_data[clean_data.rating != 'n']\n",
        "\n",
        "  # Cast rating as integer\n",
        "  clean_data['rating'] = clean_data['rating'].astype(int)\n",
        "\n",
        "  # Convert verified purhcase to yes or no\n",
        "  clean_data['verified_purchase'] = clean_data['verified_purchase'].map({True: 'Yes', False: 'No'}) \n",
        "\n",
        "  # Convert date to datetime\n",
        "  clean_data['date'] = pd.to_datetime(clean_data['review_date'])\n",
        "\n",
        "  return clean_data\n",
        "\n",
        "def contractions(s):\n",
        "  \"\"\"Replace contractions.\"\"\" \n",
        "  s = re.sub(r\"won’t\", \"will not\",s)\n",
        "  s = re.sub(r\"would’t\", \"would not\",s)\n",
        "  s = re.sub(r\"could’t\", \"could not\",s)\n",
        "  s = re.sub(r\"\\’d\", \" would\",s)\n",
        "  s = re.sub(r\"can\\’t\", \"can not\",s)\n",
        "  s = re.sub(r\"n\\’t\", \" not\", s)\n",
        "  s = re.sub(r\"\\’re\", \" are\", s)\n",
        "  s = re.sub(r\"\\’s\", \" is\", s)\n",
        "  s = re.sub(r\"\\’ll\", \" will\", s)\n",
        "  s = re.sub(r\"\\’t\", \" not\", s)\n",
        "  s = re.sub(r\"\\’ve\", \" have\", s)\n",
        "  s = re.sub(r\"\\’m\", \" am\", s)\n",
        "\n",
        "  return s\n",
        "\n",
        "def final_clean_reviews(text):\n",
        "    '''\n",
        "    Make text lowercase, remove text in square brackets, remove links, remove punctuation\n",
        "    and remove words containing numbers.\n",
        "    '''\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "grqhoYocV2NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean data\n",
        "clean_data = clean_reviews()\n",
        "\n",
        "# Replace contractions\n",
        "clean_data['pre_process'] = clean_data['reviews'].apply(lambda x: contractions(x))\n",
        "\n",
        "# Remove any remaining non-alpha characters\n",
        "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: \" \".join([re.sub('[^A-Za-z]+','', x) for x in nltk.word_tokenize(x)]))\n",
        "\n",
        "# Remove any remaining brackets, links, punctuation, words, numbers\n",
        "clean_data['pre_process'] = clean_data['pre_process'].apply(lambda x: final_clean_reviews(x))"
      ],
      "metadata": {
        "id": "5eOiS34faFpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data.head()"
      ],
      "metadata": {
        "id": "V2R0d7ameyPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for null values\n",
        "clean_data.isnull().sum()"
      ],
      "metadata": {
        "id": "fsIABWxAmRC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Amazon Reviews into two temporal dataframes\n",
        "- Before the first book ban (one year prior - July 1, 2020 to June 30, 2021)\n",
        "- After the first book ban (July 1, 2021 and after until the dataset ends on October 12, 2022)"
      ],
      "metadata": {
        "id": "Ndm4Bdi_YpN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_date ='2021-07-01'\n",
        "before_ban_amz_df = clean_data.loc[clean_data['review_date'] < split_date]\n",
        "after_ban_amz_df = clean_data.loc[clean_data['review_date'] >= split_date]"
      ],
      "metadata": {
        "id": "QLVyqPjuYyxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_date ='2020-07-01'\n",
        "before_ban_amz_df = before_ban_amz_df.loc[before_ban_amz_df['review_date'] >= split_date]"
      ],
      "metadata": {
        "id": "p_MVxttrY1dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_ban_amz_df.head()"
      ],
      "metadata": {
        "id": "d9txKhBlfJtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "after_ban_amz_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "HC83wuexfLyq",
        "outputId": "8a14b695-a259-4976-967a-1f2a4d2c5e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       product_name  rating verified_purchase review_date  \\\n",
              "2  Ace Spades Faridah Abike Iyimide       5               Yes  2022-09-12   \n",
              "3  Ace Spades Faridah Abike Iyimide       4               Yes  2022-08-10   \n",
              "4  Ace Spades Faridah Abike Iyimide       5               Yes  2021-07-05   \n",
              "5  Ace Spades Faridah Abike Iyimide       4               Yes  2021-07-03   \n",
              "6  Ace Spades Faridah Abike Iyimide       4               Yes  2021-07-20   \n",
              "\n",
              "                                             reviews  \\\n",
              "2  Wow I ordered this book for my teenage daughte...   \n",
              "3  Definitely a YA novel Great plot, childish cha...   \n",
              "4  A most timely book. This a very engrossing sto...   \n",
              "5  Taut thriller Two students at a ritzy preparat...   \n",
              "6  A dark thriller that delves into racism Devon ...   \n",
              "\n",
              "                                         pre_process       date  \n",
              "2  wow i ordered this book for my teenage daughte... 2022-09-12  \n",
              "3  definitely a ya novel great plot  childish cha... 2022-08-10  \n",
              "4  a most timely book  this a very engrossing sto... 2021-07-05  \n",
              "5  taut thriller two students at a ritzy preparat... 2021-07-03  \n",
              "6  a dark thriller that delves into racism devon ... 2021-07-20  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff82a044-8299-443c-a12b-2222fbe25531\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>rating</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_date</th>\n",
              "      <th>reviews</th>\n",
              "      <th>pre_process</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2022-09-12</td>\n",
              "      <td>Wow I ordered this book for my teenage daughte...</td>\n",
              "      <td>wow i ordered this book for my teenage daughte...</td>\n",
              "      <td>2022-09-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>Definitely a YA novel Great plot, childish cha...</td>\n",
              "      <td>definitely a ya novel great plot  childish cha...</td>\n",
              "      <td>2022-08-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>A most timely book. This a very engrossing sto...</td>\n",
              "      <td>a most timely book  this a very engrossing sto...</td>\n",
              "      <td>2021-07-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2021-07-03</td>\n",
              "      <td>Taut thriller Two students at a ritzy preparat...</td>\n",
              "      <td>taut thriller two students at a ritzy preparat...</td>\n",
              "      <td>2021-07-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ace Spades Faridah Abike Iyimide</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2021-07-20</td>\n",
              "      <td>A dark thriller that delves into racism Devon ...</td>\n",
              "      <td>a dark thriller that delves into racism devon ...</td>\n",
              "      <td>2021-07-20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff82a044-8299-443c-a12b-2222fbe25531')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff82a044-8299-443c-a12b-2222fbe25531 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff82a044-8299-443c-a12b-2222fbe25531');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pickle/Save Cleaned Dataframes"
      ],
      "metadata": {
        "id": "Fu8Nngk4QgEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save cleaned banned book data\n",
        "clean_df.to_pickle('/content/drive/MyDrive/Colab Notebooks/data/cleaned_trained_data/cleaned_topic_modeling.pkl')"
      ],
      "metadata": {
        "id": "KV4CZOCRIUys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save reviews\n",
        "before_ban_amz_df.to_pickle('/content/drive/MyDrive/Colab Notebooks/data/cleaned_trained_data/before_ban_amazon_review_data.pkl')\n",
        "after_ban_amz_df.to_pickle('/content/drive/MyDrive/Colab Notebooks/data/cleaned_trained_data/after_ban_amazon_review_data.pkl')\n",
        "clean_data.to_pickle('/content/drive/MyDrive/Colab Notebooks/data/cleaned_trained_data/all_amazon_review_data.pkl')"
      ],
      "metadata": {
        "id": "Yvb966qRVara"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}